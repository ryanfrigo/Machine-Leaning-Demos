{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8951d5f5",
   "metadata": {
    "id": "8951d5f5"
   },
   "source": [
    "# Optical Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e3964a",
   "metadata": {
    "code_folding": [],
    "id": "80e3964a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1267ae20",
   "metadata": {
    "code_folding": [],
    "id": "1267ae20"
   },
   "outputs": [],
   "source": [
    "# Load in data\n",
    "\n",
    "train_data = pd.read_csv('Letters_train.csv')\n",
    "test_data = pd.read_csv('Letters_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f17875",
   "metadata": {},
   "source": [
    "## Predicting whether a letter is B or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2e726",
   "metadata": {
    "id": "a7c2e726"
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a6931e",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "a5a6931e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "train_data['isB'] = train_data['letter'].apply(lambda x: 'Yes' if x == 'B' else 'No')\n",
    "test_data['isB'] = test_data['letter'].apply(lambda x: 'Yes' if x == 'B' else 'No')\n",
    "baseline_1_acc = (test_data['isB'] == 'No').mean()\n",
    "print(f'Baseline Test Accuracy: {baseline_1_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f7dca",
   "metadata": {
    "id": "eb0f7dca"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fba5965",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "7fba5965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9401\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.drop(['Unnamed: 0', 'letter', 'isB'], axis=1)\n",
    "y_train = train_data['isB']\n",
    "X_test = test_data.drop(['Unnamed: 0', 'letter', 'isB'], axis=1)\n",
    "y_test = test_data['isB']\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=2023, max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "model_1b_acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Logistic Regression Test Accuracy: {model_1b_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495157d",
   "metadata": {
    "id": "7495157d"
   },
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94594df9",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "94594df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test AUC: 0.9785\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = logistic_model.predict_proba(X_test)[:, 1]\n",
    "model_1b_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Logistic Regression Test AUC: {model_1b_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75df07",
   "metadata": {
    "id": "ba75df07"
   },
   "source": [
    "### Cross-validated CART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6132e51",
   "metadata": {
    "id": "a6132e51"
   },
   "source": [
    "In selecting the `ccp_alpha`, I ran a pretty standard grid search, tossing a bunch of `ccp_alpha` values into the mix to see what stuck. I split the training data into five equal chunks and rotated them through a cycle of training and validation, a method you might know as 5-fold cross-validation. The `ccp_alpha` that came out on top was the one that, on average, guessed right more often than the others when it was put to the test. It's like finding the sweet spot where the tree is just complex enough to get a good read on the data without getting so tangled up that it can't make sense of anything new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee59e95",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "dee59e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV CART Test Accuracy: 0.9401\n",
      "Best ccp_alpha: 0.0007\n"
     ]
    }
   ],
   "source": [
    "cart_model = DecisionTreeClassifier(random_state=2023)\n",
    "ccp_alpha_values = np.linspace(0.0001, 0.02, 100)\n",
    "param_grid = {'ccp_alpha': ccp_alpha_values}\n",
    "cart_cv = GridSearchCV(cart_model, param_grid, cv=5, scoring='accuracy')\n",
    "cart_cv.fit(X_train, y_train)\n",
    "model_1d_best_ccp_alpha = cart_cv.best_params_['ccp_alpha']\n",
    "best_cart_model = cart_cv.best_estimator_\n",
    "y_pred_cart = best_cart_model.predict(X_test)\n",
    "model_1d_acc = accuracy_score(y_test, y_pred_cart)\n",
    "print(f'CV CART Test Accuracy: {model_1d_acc:.4f}')\n",
    "print(f'Best ccp_alpha: {model_1d_best_ccp_alpha:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65edd8a",
   "metadata": {
    "id": "f65edd8a"
   },
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7acb2",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "28f7acb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state=2023)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "model_1e_acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'Random Forest Test Accuracy: {model_1e_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53648a60",
   "metadata": {
    "id": "53648a60"
   },
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bfd25",
   "metadata": {
    "id": "e74bfd25"
   },
   "source": [
    "In comparing the performance of the logistic regression, CART, and Random Forest models, it is evident that the Random Forest model outperforms the others in terms of accuracy on the test set. While logistic regression and CART exhibit identical accuracy, Random Forest advances with a higher score, marking it as the superior model for this specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015fa9c",
   "metadata": {
    "code_folding": [],
    "id": "0015fa9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.940107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.940107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.983957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0  Logistic Regression  0.940107\n",
       "1                 CART  0.940107\n",
       "2        Random Forest  0.983957"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'CART', 'Random Forest'],\n",
    "    'Accuracy': [model_1b_acc, model_1d_acc, model_1e_acc]\n",
    "})\n",
    "\n",
    "performance_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf5897",
   "metadata": {},
   "source": [
    "## Predicting whether a letter is A, B, P, or R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2553f29",
   "metadata": {
    "id": "e2553f29"
   },
   "source": [
    "Part A: Baseline Model (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d84b11f",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "3d84b11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.2439\n"
     ]
    }
   ],
   "source": [
    "y_train_multiclass = train_data['letter']\n",
    "y_test_multiclass = test_data['letter']\n",
    "most_frequent_class = y_train_multiclass.mode()[0]\n",
    "baseline_predictions = [most_frequent_class] * len(y_test_multiclass)\n",
    "baseline_2_acc = accuracy_score(y_test_multiclass, baseline_predictions)\n",
    "print(f'Baseline Test Accuracy: {baseline_2_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f682d",
   "metadata": {
    "id": "555f682d"
   },
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8860299d",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "8860299d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Test Accuracy: 0.9102\n"
     ]
    }
   ],
   "source": [
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train_multiclass)\n",
    "y_pred_lda = lda_model.predict(X_test)\n",
    "model_2b_acc = accuracy_score(y_test_multiclass, y_pred_lda)\n",
    "print(f'LDA Test Accuracy: {model_2b_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75cc6e",
   "metadata": {
    "id": "3c75cc6e"
   },
   "source": [
    "### Cross-validated CART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfa50d",
   "metadata": {
    "id": "21dfa50d"
   },
   "source": [
    "To tune the ccp_alpha parameter of the CART model for the multi-class classification problem, I employed a grid search combined with 5-fold cross-validation. The training data was divided into five subsets, and the model was trained and validated on these subsets iteratively. Each ccp_alpha value was assessed based on its ability to maximize accuracy across the validation sets. The ccp_alpha that yielded the highest average accuracy was selected as the optimal parameter for the final model. This approach ensures that the model is neither too complex (which would risk overfitting) nor too simplistic (which would not capture sufficient detail), aiming for a balance that promotes good generalization to unseen data.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80208cc3",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "80208cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Test Accuracy: 0.9294\n"
     ]
    }
   ],
   "source": [
    "cart_model_multiclass = DecisionTreeClassifier(random_state=2023)\n",
    "cart_cv_multiclass = GridSearchCV(cart_model_multiclass, param_grid, cv=5, scoring='accuracy')\n",
    "cart_cv_multiclass.fit(X_train, y_train_multiclass)\n",
    "model_2c_best_ccp_alpha = cart_cv_multiclass.best_params_['ccp_alpha']\n",
    "best_cart_model_multiclass = cart_cv_multiclass.best_estimator_\n",
    "y_pred_cart_multiclass = best_cart_model_multiclass.predict(X_test)\n",
    "model_2c_acc = accuracy_score(y_test_multiclass, y_pred_cart_multiclass)\n",
    "print(f'CART Test Accuracy: {model_2c_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31acb6",
   "metadata": {
    "id": "1a31acb6"
   },
   "source": [
    "### Vanilla Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d3724",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "ce7d3724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CV Random Forest Test Accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "vanilla_bagging_model = RandomForestClassifier(max_features=X_train.shape[1], random_state=2023)\n",
    "vanilla_bagging_model.fit(X_train, y_train_multiclass)\n",
    "y_pred_vanilla_bagging = vanilla_bagging_model.predict(X_test)\n",
    "model_2d_acc = accuracy_score(y_test_multiclass, y_pred_vanilla_bagging)\n",
    "\n",
    "print(f'No CV Random Forest Test Accuracy: {model_2d_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d3365",
   "metadata": {
    "id": "903d3365"
   },
   "source": [
    "### Cross-validated Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad086a5",
   "metadata": {
    "id": "0ad086a5"
   },
   "source": [
    "In fine-tuning the Random Forest model, I conducted a grid search with 5-fold cross-validation to identify the optimal max_features value. This parameter controls the subset of features considered when splitting each node in the decision trees. The cross-validation process involved partitioning the training set into five distinct subsets, systematically training the model on four subsets and validating on the remaining one. The max_features value that led to the highest validation accuracy was selected, suggesting that this parameter setting allows the ensemble of trees to best generalize from the training data to unseen data. The optimal value of max_features indicates that using a small subset of features at each split can enhance the model's diversity and predictive power.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bae54c",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "f2bae54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Random Forest Test Accuracy: 0.9765\n"
     ]
    }
   ],
   "source": [
    "max_features_range = np.arange(1, X_train.shape[1] + 1, 1)\n",
    "param_grid_rf = {'max_features': max_features_range}\n",
    "rf_cv_model = GridSearchCV(RandomForestClassifier(random_state=2023), param_grid_rf, cv=5, scoring='accuracy')\n",
    "rf_cv_model.fit(X_train, y_train_multiclass)\n",
    "model_2e_best_max_features = rf_cv_model.best_params_['max_features']\n",
    "best_rf_model = rf_cv_model.best_estimator_\n",
    "y_pred_rf_cv = best_rf_model.predict(X_test)\n",
    "model_2e_acc = accuracy_score(y_test_multiclass, y_pred_rf_cv)\n",
    "print(f'CV Random Forest Test Accuracy: {model_2e_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969e7f2",
   "metadata": {
    "id": "1969e7f2"
   },
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd4e72",
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "f9bd4e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC Test Accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "gbc_model = GradientBoostingClassifier(n_estimators=200, max_leaf_nodes=10, random_state=2023)\n",
    "gbc_model.fit(X_train, y_train_multiclass)\n",
    "y_pred_gbc = gbc_model.predict(X_test)\n",
    "model_2f_acc = accuracy_score(y_test_multiclass, y_pred_gbc)\n",
    "print(f'GBC Test Accuracy: {model_2f_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882bcbb",
   "metadata": {
    "id": "1882bcbb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
